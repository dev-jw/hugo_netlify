---
title: "iOSåº•å±‚åŸç†æ¢ç´¢-æ¶ˆæ¯å‘é€ä¸è½¬å‘"
date: 2020-09-18T22:07:29+08:00
draft: true
tags: [iOS]
url:  "message"
---

åœ¨`cache_t`ä¸­ï¼Œä»‹ç»äº†æ–¹æ³•çš„ç¼“å­˜ï¼Œé‚£ä¹ˆæ–¹æ³•å…·ä½“æ˜¯ä»€ä¹ˆï¼Ÿæ–¹æ³•çš„è°ƒç”¨è¿‡ç¨‹åˆæ˜¯æ€ä¹ˆæ ·çš„å‘¢ï¼Ÿæœ¬æ¥å°†å¯¹æ–¹æ³•è¿›è¡Œåˆ†æ

åŒæ ·çš„ï¼Œå…ˆæå‡ºå‡ ä¸ªé—®é¢˜ï¼š

- ä»€ä¹ˆæ˜¯ Runtime

- æ–¹æ³•çš„æœ¬è´¨
- æ–¹æ³•å¿«é€ŸæŸ¥æ‰¾æµç¨‹
- æ–¹æ³•æ…¢é€ŸæŸ¥æ‰¾æµç¨‹

### Runtime

**ä»€ä¹ˆæ˜¯Runtime**

`Runtime`æ˜¯ä¸€å¥— APIï¼Œç”± cã€c++ã€æ±‡ç¼–ä¸€èµ·å†™æˆçš„ï¼Œä¸º `Objective-c` æä¾›äº†è¿è¡Œæ—¶çš„èƒ½åŠ›

- è¿è¡Œæ—¶ï¼š`ä»£ç è·‘èµ·æ¥ï¼Œè¢«è£…è½½åˆ°å†…å­˜ä¸­`çš„è¿‡ç¨‹ï¼Œå¦‚æœæ­¤æ—¶å‡ºé”™ï¼Œåˆ™ç¨‹åºä¼šå´©æºƒï¼Œæ˜¯ä¸€ä¸ª`åŠ¨æ€`é˜¶æ®µ
- ç¼–è¯‘æ—¶ï¼š`æºä»£ç ç¿»è¯‘æˆæœºå™¨èƒ½è¯†åˆ«çš„ä»£ç `çš„è¿‡ç¨‹ï¼Œä¸»è¦æ˜¯å¯¹è¯­è¨€è¿›è¡Œæœ€åŸºæœ¬çš„æ£€æŸ¥æŠ¥é”™ï¼Œå³è¯æ³•åˆ†æã€è¯­æ³•åˆ†æç­‰ï¼Œæ˜¯ä¸€ä¸ª`é™æ€`çš„é˜¶æ®µ

**è°ƒç”¨Runtimeçš„æ–¹å¼**

- Objective-C Codeï¼Œå¦‚`[person run]`
- NSObject APIï¼Œå¦‚`isKindofClass`

- Runtime APiï¼Œå¦‚`class_getInstanceSize`

### æ–¹æ³•çš„æœ¬è´¨

é€šè¿‡ clang ç¼–è¯‘åï¼Œå¯ä»¥çœ‹åˆ°åº•å±‚ä»£ç ï¼š

```objective-c
//main.mä¸­æ–¹æ³•çš„è°ƒç”¨
Person *person = [Person alloc];
[person run];

//ğŸ‘‡clangç¼–è¯‘åçš„åº•å±‚å®ç°
Person *person = ((Person *(*)(id, SEL))(void *)objc_msgSend)((id)objc_getClass("Person"), sel_registerName("alloc"));
((void (*)(id, SEL))(void *)objc_msgSend)((id)person, sel_registerName("run"));

```

[person run]ä¼šè¢«ç¼–è¯‘ä¸ºï¼š`objc_msgSend(person, sel_registerName("run"))`ï¼Œå³`objc_msgSend(æ¶ˆæ¯æ¥æ”¶è€…, æ–¹æ³•ç¼–å·)`

æ²¡é”™ï¼Œæ–¹æ³•çš„æœ¬è´¨å°±æ˜¯**é€šè¿‡`objc_msgSendå‡½æ•°`å‘é€æ¶ˆæ¯**

```objective-c
id objc_msgSend(id self, SEL op, ...)
```

`objc_msgSend`è¿™æ˜¯ä¸€ä¸ªå¯å˜å‚æ•°å‡½æ•°ã€‚ç¬¬äºŒä¸ªå‚æ•°ç±»å‹æ˜¯SELï¼Œåœ¨ OC ä¸­æ˜¯ `selector` æ–¹æ³•é€‰æ‹©å™¨

```objective-c
typedef struct objc_selector *SEL;
```

`objc_selector`æ˜¯ä¸€ä¸ªæ˜ å°„åˆ°æ–¹æ³•çš„ C å­—ç¬¦ä¸²ã€‚éœ€è¦æ³¨æ„çš„æ˜¯`@selector()`é€‰æ‹©åªä¸å‡½æ•°åæœ‰å…³ã€‚

- ä¸åŒç±»ä¸­ç›¸åŒåå­—çš„æ–¹æ³•æ‰€å¯¹åº”çš„æ–¹æ³•é€‰æ‹©å™¨æ˜¯ç›¸åŒçš„
- æ–¹æ³•åå­—ç›¸åŒè€Œå˜é‡ç±»å‹ä¸åŒï¼Œä¹Ÿä¼šå¯¼è‡´å®ƒä»¬å…·æœ‰ç›¸åŒçš„æ–¹æ³•é€‰æ‹©å™¨

å› æ­¤ï¼Œ**OC æ˜¯ä¸æ”¯æŒå‡½æ•°é‡è½½**

> å¦‚æœå¤–éƒ¨å®šä¹‰äº†Cå‡½æ•°å¹¶è°ƒç”¨å¦‚`void fly() {}`ï¼Œåœ¨clangç¼–è¯‘ä¹‹åè¿˜æ˜¯`fly()`è€Œä¸æ˜¯é€šè¿‡`objc_msgSend`å»è°ƒç”¨ã€‚
>
> å› ä¸ºå‘é€æ¶ˆæ¯å°±æ˜¯æ‰¾å‡½æ•°å®ç°çš„è¿‡ç¨‹ï¼Œè€ŒCå‡½æ•°å¯ä»¥é€šè¿‡`å‡½æ•°å`â€”â€”`æŒ‡é’ˆ`å°±å¯ä»¥æ‰¾åˆ°

### æ–¹æ³•æŸ¥æ‰¾æµç¨‹ â€”â€” objc_msgSendæºç è§£æ

> æ¶ˆæ¯æŸ¥æ‰¾æµç¨‹å…¶å®æ˜¯é€šè¿‡ä¸Šå±‚çš„`æ–¹æ³•ç¼–å·sel`å‘é€æ¶ˆæ¯`objc_msgSend`æ‰¾åˆ°`å…·ä½“å®ç°imp`çš„è¿‡ç¨‹

`objc_msgSend`æ˜¯ç”¨æ±‡ç¼–å†™çš„ï¼Œæ˜¯å› ä¸ºï¼š

- C è¯­è¨€ä¸èƒ½é€šè¿‡å†™ä¸€ä¸ªå‡½æ•°ï¼Œä¿ç•™æœªçŸ¥çš„å‚æ•°ï¼Œè·³è½¬åˆ°ä»»æ„çš„æŒ‡é’ˆï¼Œè€Œæ±‡ç¼–æœ‰å¯„å­˜å™¨
- å¯¹äºä¸€äº›è°ƒç”¨é¢‘ç‡å¤ªé«˜çš„å‡½æ•°æˆ–æ“ä½œï¼Œä½¿ç”¨æ±‡ç¼–æ¥å®ç°ï¼Œèƒ½å¤Ÿæé«˜æ•ˆç‡å’Œæ€§èƒ½ï¼Œå®¹æ˜“è¢«æœºå™¨æ¥è¯†åˆ«

#### å¿«é€ŸæŸ¥æ‰¾æµç¨‹

åœ¨`obj4-781`é‡Œé¢çš„`objc-msg-arm64.s`æ–‡ä»¶ä¸­ï¼Œ`objc_msgSend`æ±‡ç¼–æºç ï¼š

```asm
/********************************************************************
 *
 * id objc_msgSend(id self, SEL _cmd, ...);
 * IMP objc_msgLookup(id self, SEL _cmd, ...);
 * 
 * objc_msgLookup ABI:
 * IMP returned in x17
 * x16 reserved for our use but not used
 *
 ********************************************************************/

#if SUPPORT_TAGGED_POINTERS
	.data
	.align 3
	.globl _objc_debug_taggedpointer_classes
_objc_debug_taggedpointer_classes:
	.fill 16, 8, 0
	.globl _objc_debug_taggedpointer_ext_classes
_objc_debug_taggedpointer_ext_classes:
	.fill 256, 8, 0
#endif

	ENTRY _objc_msgSend
	UNWIND _objc_msgSend, NoFrame

	cmp	p0, #0			// nil check and tagged pointer check
#if SUPPORT_TAGGED_POINTERS
	b.le	LNilOrTagged		//  (MSB tagged pointer looks negative)
#else
	b.eq	LReturnZero
#endif
	ldr	p13, [x0]		// p13 = isa
	GetClassFromIsa_p16 p13		// p16 = class
LGetIsaDone:
	// calls imp or objc_msgSend_uncached
	CacheLookup NORMAL, _objc_msgSend
```

> p0è¡¨ç¤º0å¯„å­˜å™¨çš„æŒ‡é’ˆï¼Œx0 è¡¨ç¤ºå®ƒçš„å€¼ã€‚

**åˆ†ææ±‡ç¼–ä»£ç **

è¿›å…¥åˆ°`_objc_msgSend`æ–¹æ³•

- æ¯”è¾ƒ`p0`æ˜¯å¦ä¸ºç©ºï¼Œå³æ¶ˆæ¯æ¥æ”¶è€…æ˜¯å¦ä¸ºç©º
- åˆ¤æ–­æ˜¯å¦ä¸º`tagged_pointers`(å°å¯¹è±¡ç±»å‹)ï¼Œä¹‹åä¼šå•ç‹¬åˆ†æ`tagged_pointers`
- å–å‡º`x0`ï¼Œå­˜å…¥`p13`å¯„å­˜å™¨ï¼Œå³ä»`receiver`ä¸­å–å‡º`isa`å­˜å…¥`p13`å¯„å­˜å™¨
- é€šè¿‡`GetClassFromIsa_p16`ï¼Œè·å–`receiver`ä¸­çš„ç±»ä¿¡æ¯
- è¿›å…¥`CacheLookup`ï¼Œæ ¹æ®å½“å‰ç±»çš„ç¼“å­˜æŸ¥æ‰¾`imp`â€”â€”**å¿«é€ŸæŸ¥æ‰¾æµç¨‹**

`GetClassFromIsa_p16`æ±‡ç¼–æºç ï¼š

```asm
/********************************************************************
 * GetClassFromIsa_p16 src
 * src is a raw isa field. Sets p16 to the corresponding class pointer.
 * The raw isa might be an indexed isa to be decoded, or a
 * packed isa that needs to be masked.
 *
 * On exit:
 *   $0 is unchanged
 *   p16 is a class pointer
 *   x10 is clobbered
 ********************************************************************/

#if SUPPORT_INDEXED_ISA
	.align 3
	.globl _objc_indexed_classes
_objc_indexed_classes:
	.fill ISA_INDEX_COUNT, PTRSIZE, 0
#endif

.macro GetClassFromIsa_p16 /* src */

#if SUPPORT_INDEXED_ISA
	// Indexed isa
	mov	p16, $0			// optimistically set dst = src
	tbz	p16, #ISA_INDEX_IS_NPI_BIT, 1f	// done if not non-pointer isa
	// isa in p16 is indexed
	adrp	x10, _objc_indexed_classes@PAGE
	add	x10, x10, _objc_indexed_classes@PAGEOFF
	ubfx	p16, p16, #ISA_INDEX_SHIFT, #ISA_INDEX_BITS  // extract index
	ldr	p16, [x10, p16, UXTP #PTRSHIFT]	// load class from array
1:

#elif __LP64__
	// 64-bit packed isa
	and	p16, $0, #ISA_MASK

#else
	// 32-bit raw isa
	mov	p16, $0

#endif

.endmacro
```

`and p16, $0, #ISA_MASK`ç­‰åŒäº`isa & ISA_MASK`ï¼Œä¹Ÿå°±æ˜¯è·å– isa æŒ‡é’ˆä¸­ `shiftcls` ä¸­çš„ç±»ä¿¡æ¯

`CacheLookup`æºç ï¼š

```asm
.macro CacheLookup
	//
	// Restart protocol:
	//
	//   As soon as we're past the LLookupStart$1 label we may have loaded
	//   an invalid cache pointer or mask.
	//
	//   When task_restartable_ranges_synchronize() is called,
	//   (or when a signal hits us) before we're past LLookupEnd$1,
	//   then our PC will be reset to LLookupRecover$1 which forcefully
	//   jumps to the cache-miss codepath which have the following
	//   requirements:
	//
	//   GETIMP:
	//     The cache-miss is just returning NULL (setting x0 to 0)
	//
	//   NORMAL and LOOKUP:
	//   - x0 contains the receiver
	//   - x1 contains the selector
	//   - x16 contains the isa
	//   - other registers are set as per calling conventions
	//
LLookupStart$1:

	// p1 = SEL, p16 = isa
	ldr	p11, [x16, #CACHE]				// p11 = mask|buckets

#if CACHE_MASK_STORAGE == CACHE_MASK_STORAGE_HIGH_16
	and	p10, p11, #0x0000ffffffffffff	// p10 = buckets
	and	p12, p1, p11, LSR #48		// x12 = _cmd & mask
#elif CACHE_MASK_STORAGE == CACHE_MASK_STORAGE_LOW_4
	and	p10, p11, #~0xf			// p10 = buckets
	and	p11, p11, #0xf			// p11 = maskShift
	mov	p12, #0xffff
	lsr	p11, p12, p11				// p11 = mask = 0xffff >> p11
	and	p12, p1, p11				// x12 = _cmd & mask
#else
#error Unsupported cache mask storage for ARM64.
#endif


	add	p12, p10, p12, LSL #(1+PTRSHIFT)
		             // p12 = buckets + ((_cmd & mask) << (1+PTRSHIFT))

	ldp	p17, p9, [x12]		// {imp, sel} = *bucket
1:	cmp	p9, p1			// if (bucket->sel != _cmd)
	b.ne	2f			//     scan more
	CacheHit $0			// call or return imp
	
2:	// not hit: p12 = not-hit bucket
	CheckMiss $0			// miss if bucket->sel == 0
	cmp	p12, p10		// wrap if bucket == buckets
	b.eq	3f
	ldp	p17, p9, [x12, #-BUCKET_SIZE]!	// {imp, sel} = *--bucket
	b	1b			// loop

3:	// wrap: p12 = first bucket, w11 = mask
#if CACHE_MASK_STORAGE == CACHE_MASK_STORAGE_HIGH_16
	add	p12, p12, p11, LSR #(48 - (1+PTRSHIFT))
					// p12 = buckets + (mask << 1+PTRSHIFT)
#elif CACHE_MASK_STORAGE == CACHE_MASK_STORAGE_LOW_4
	add	p12, p12, p11, LSL #(1+PTRSHIFT)
					// p12 = buckets + (mask << 1+PTRSHIFT)
#else
#error Unsupported cache mask storage for ARM64.
#endif

	// Clone scanning loop to miss instead of hang when cache is corrupt.
	// The slow path may detect any corruption and halt later.

	ldp	p17, p9, [x12]		// {imp, sel} = *bucket
1:	cmp	p9, p1			// if (bucket->sel != _cmd)
	b.ne	2f			//     scan more
	CacheHit $0			// call or return imp
	
2:	// not hit: p12 = not-hit bucket
	CheckMiss $0			// miss if bucket->sel == 0
	cmp	p12, p10		// wrap if bucket == buckets
	b.eq	3f
	ldp	p17, p9, [x12, #-BUCKET_SIZE]!	// {imp, sel} = *--bucket
	b	1b			// loop

LLookupEnd$1:
LLookupRecover$1:
3:	// double wrap
	JumpMiss $0

.endmacro
```

åˆ†ææŸ¥æ‰¾æµç¨‹ï¼š

- `ldr p11, [x16, #CACHE]`ï¼š`x16`å­˜å‚¨çš„æ˜¯ isaï¼Œ`#CACHE`æ˜¯ä¸ªå®å®šä¹‰ï¼Œè¡¨ç¤º 16 ä¸ªå­—èŠ‚ï¼›`[x16, #CACHE]`è¡¨ç¤ºç±»å¯¹è±¡`å†…å­˜åœ°å€åç§»16å­—èŠ‚`å¾—åˆ°`cache`

- `and p10, p11, #0x0000ffffffffffff`ï¼šå°† `cache` å’Œ `0x0000ffffffffffff`è¿›è¡Œ`&`è¿ç®—ï¼Œå¾—åˆ° `buckets` å­˜å…¥ `p10` å¯„å­˜å™¨

- `and p12, p1, p11, LSR #48`ï¼šå°† `cache` è¿›è¡Œå³ç§» 48 ä½ï¼Œå¾—åˆ° `mask`ï¼Œå­˜å…¥ `p11` å¹¶ä¸ `p1` è¿›è¡Œ`&`æ“ä½œï¼Œå³ `_cmd & mask = sel & mask`å¾—åˆ°å“ˆå¸Œç´¢å¼•å­˜å…¥ `p12` å¯„å­˜å™¨

  ```c++
  static inline mask_t cache_hash(SEL sel, mask_t mask) 
  {
      return (mask_t)(uintptr_t)sel & mask;
  }
  ```

- `add p12, p10, p12, LSL #(1+PTRSHIFT)`ï¼š

  - `PTRSHIFT`æ˜¯å®å®šä¹‰ï¼Œåœ¨ `arm64` ä¸‹ç­‰äº `3`ï¼Œ*1+PTRSHIFT = 4* 
  - `p10, p12, LSL #(1+PTRSHIFT)`å³å·¦ç§» 4 ä½ï¼ˆç»“æ„ä½“ `bucket_t` å  16 å­—èŠ‚ï¼Œselã€imp å„å  8ï¼‰ï¼Œ`å“ˆå¸Œç´¢å¼•*bucketå ç”¨å†…å­˜å¤§å°`ï¼Œå¾—åˆ°`buckets`é¦–åœ°å€åœ¨`å®é™…å†…å­˜`ä¸­çš„`åç§»é‡`
  - `p12, p10, p12, LSL #(1+PTRSHIFT)`è¡¨ç¤ºé€šè¿‡`buckets`é¦–åœ°å€+å®é™…åç§»é‡ï¼Œè·å–å“ˆå¸Œç´¢å¼•å¯¹åº”çš„`bucket`

- `ldp p17, p9, [x12]`æ ¹æ®è·å–çš„`bucket`ï¼Œå–å‡ºå…¶ä¸­çš„`sel`å­˜å…¥`p17`ï¼Œå³`p17 = sel`ï¼Œå–å‡º`imp`å­˜å…¥`p9`ï¼Œå³`p9 = imp`

- å¼€å¯ç¬¬ä¸€æ¬¡å¾ªç¯

  - æ¯”è¾ƒè·å–çš„`bucket`ä¸­`sel` ä¸ `objc_msgSend`çš„ç¬¬äºŒä¸ªå‚æ•°çš„`_cmd(å³p1)`æ˜¯å¦ç›¸ç­‰
  - å¦‚æœ`ç›¸ç­‰`ï¼Œåˆ™ç›´æ¥è·³è½¬è‡³`CacheHit`ï¼Œå³`ç¼“å­˜å‘½ä¸­`ï¼Œè¿”å›`imp`
  - å¦‚æœä¸ç›¸ç­‰ï¼Œæœ‰ä»¥ä¸‹ä¸¤ç§æƒ…å†µ
    - å¦‚æœä¸€ç›´éƒ½æ‰¾ä¸åˆ°ï¼Œç›´æ¥è·³è½¬è‡³`CheckMiss`ï¼Œå› ä¸º`$0`æ˜¯`normal`ï¼Œä¼šè·³è½¬è‡³`__objc_msgSend_uncached`ï¼Œå³è¿›å…¥`æ…¢é€ŸæŸ¥æ‰¾æµç¨‹`
    - å¦‚æœ`æ ¹æ®indexè·å–çš„bucket` ç­‰äº `buckets` çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œåˆ™`äººä¸º`çš„å°†`å½“å‰bucketè®¾ç½®ä¸ºbucketsçš„æœ€åä¸€ä¸ªå…ƒç´ `ï¼ˆé€šè¿‡`bucketsé¦–åœ°å€+maskå³ç§»44ä½`ï¼ˆç­‰åŒäºå·¦ç§»4ä½ï¼‰ç›´æ¥`å®šä½åˆ°buckerçš„æœ€åä¸€ä¸ªå…ƒç´ `ï¼‰ï¼Œæ¥ç€æ‰§è¡Œä¸‹é¢çš„æ±‡ç¼–ï¼Œæ¥åˆ°ç¬¬äºŒæ¬¡å¾ªç¯

- ç¬¬äºŒæ¬¡å¾ªç¯

  - é‡å¤ç¬¬ä¸€æ¬¡å¾ªç¯çš„æ“ä½œï¼Œä¸ä¹‹å”¯ä¸€ä¸åŒçš„æ˜¯ï¼š

    åœ¨ `sel != _cmd` æ—¶ï¼Œå¦‚æœå½“å‰çš„ `bucket` ç­‰äº `buckes` çš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œåˆ™ç›´æ¥è·³è½¬è‡³ `JumpMiss`ï¼Œæ­¤æ—¶çš„`$0`æ˜¯`normal`ï¼Œä¹Ÿæ˜¯ç›´æ¥è·³è½¬è‡³`__objc_msgSend_uncached`ï¼Œå³è¿›å…¥`æ…¢é€ŸæŸ¥æ‰¾æµç¨‹`

> ä¸¤æ¬¡å¾ªç¯çš„ç›®çš„ï¼šé˜²æ­¢ä¸æ–­å¾ªç¯çš„è¿‡ç¨‹ä¸­å¤šçº¿ç¨‹å¹¶å‘ï¼Œæ­£å¥½ç¼“å­˜æ›´æ–°äº†

åœ¨è¿™ç¯‡æ–‡ç« [Obj-C Optimization: The faster objc_msgSend](http://www.mulle-kybernetik.com/artikel/Optimization/opti-9.html)ä¸­çœ‹åˆ°äº†è¿™æ ·ä¸€æ®µCç‰ˆæœ¬çš„objc_msgSendçš„æºç ã€‚

```c
#include <objc/objc-runtime.h>

id  c_objc_msgSend( struct objc_class /* ahem */ *self, SEL _cmd, ...)
{
   struct objc_class    *cls;
   struct objc_cache    *cache;
   unsigned int         hash;
   struct objc_method   *method;   
   unsigned int         index;
   
   if( self)
   {
      cls   = self->isa;
      cache = cls->cache;
      hash  = cache->mask;
      index = (unsigned int) _cmd & hash;
      
      do
      {
         method = cache->buckets[ index];
         if( ! method)
            goto recache;
         index = (index + 1) & cache->mask;
      }
      while( method->method_name != _cmd);
      return( (*method->method_imp)( (id) self, _cmd));
   }
   return( (id) self);

recache:
   /* ... */
   return( 0);
}
```

è™½ç„¶`objc4`çš„ç‰ˆæœ¬æœ‰æ‰€å˜åŒ–ï¼Œä½†æ˜¯åŸºæœ¬çš„æµç¨‹ä¸Šå¤§è‡´æ˜¯ç›¸ä¼¼çš„ï¼Œå¯ä»¥å‚è€ƒç†è§£ã€‚

åŒæ—¶ï¼Œä¹‹å‰åˆ†æ cache_t ä¸­çš„ `cache_t::insert`æ–¹æ³•å’Œ`objc_msgSend`æ±‡ç¼–æµç¨‹ï¼Œä¹Ÿæ˜¯éå¸¸çš„ç›¸ä¼¼çš„

**å¿«é€ŸæŸ¥æ‰¾æµç¨‹â€”â€”ç¤ºæ„å›¾**





#### æ…¢é€ŸæŸ¥æ‰¾æµç¨‹

ä¸Šé¢å¿«é€Ÿæµç¨‹ä¸­ï¼Œå¦‚æœæ²¡æœ‰å‡»ä¸­ç¼“å­˜(`CacheHit`)ï¼Œä¼šæ¥åˆ°`CheckMiss`æˆ–`JumpMiss`

`CheckMiss`æºç 

```asm
.macro CheckMiss
	// miss if bucket->sel == 0
.if $0 == GETIMP
	cbz	p9, LGetImpMiss
.elseif $0 == NORMAL
	cbz	p9, __objc_msgSend_uncached
.elseif $0 == LOOKUP
	cbz	p9, __objc_msgLookup_uncached
.else
.abort oops
.endif
.endmacro
```

`JumpMiss`æºç 

```asm
.macro JumpMiss
.if $0 == GETIMP
	b	LGetImpMiss
.elseif $0 == NORMAL
	b	__objc_msgSend_uncached
.elseif $0 == LOOKUP
	b	__objc_msgLookup_uncached
.else
.abort oops
.endif
.endmacro
```

> å½“`NORMAL`æ—¶ï¼Œ`CheckMiss`å’Œ`JumpMiss`éƒ½èµ°`__objc_msgSend_uncached`

ä»`__objc_msgSend_uncached`æ±‡ç¼–æºç ä¸­ï¼Œä¼šå‘ç°æ¥ä¸‹æ¥æ‰§è¡Œ`MethodTableLookup`å’Œ`TailCallFunctionPointer x17`æŒ‡ä»¤

```asm
STATIC_ENTRY __objc_msgSend_uncached
UNWIND __objc_msgSend_uncached, FrameWithNoSaves

// THIS IS NOT A CALLABLE C FUNCTION
// Out-of-band p16 is the class to search

MethodTableLookup
TailCallFunctionPointer x17

END_ENTRY __objc_msgSend_uncached


STATIC_ENTRY __objc_msgLookup_uncached
UNWIND __objc_msgLookup_uncached, FrameWithNoSaves
```

`MethodTableLookup`ä¹Ÿæ˜¯ä¸€ä¸ªæ¥å£å±‚å®ï¼Œä¸»è¦ç”¨äºä¿å­˜ç¯å¢ƒä¸å‡†å¤‡å‚æ•°ï¼Œæ¥è°ƒç”¨`_lookUpImpOrForward`å‡½æ•°(åœ¨objc-runtime-new.mmä¸­)

```asm
.macro MethodTableLookup
	
	// push frame
	SignLR
	stp	fp, lr, [sp, #-16]!
	mov	fp, sp

	// save parameter registers: x0..x8, q0..q7
	...

	// lookUpImpOrForward(obj, sel, cls, LOOKUP_INITIALIZE | LOOKUP_RESOLVER)
	// receiver and selector already in x0 and x1
	mov	x2, x16
	mov	x3, #3
	bl	_lookUpImpOrForward

	// IMP in x0
	mov	x17, x0
	
	// restore registers and return
	...

	mov	sp, fp
	ldp	fp, lr, [sp], #16
	AuthenticateLR

.endmacro
```

è¿™é‡Œä¼šå°† `receiverï¼Œselectorï¼Œclass` ä¸‰ä¸ªå‚æ•°å– `x0ï¼Œx1, x2` çš„å€¼ï¼Œ`behavior`è®¾ç½®ä¸º 3ï¼Œå³`LOOKUP_INITIALIZE | LOOKUP_RESOLVER`

è°ƒç”¨`lookUpImpOrForward(obj, sel, cls, LOOKUP_INITIALIZE | LOOKUP_RESOLVER)`ï¼Œå°†è¿”å›çš„ `IMP` å­˜åˆ° `x17`

**`lookUpImpOrForward`å‡½æ•°å®ç°**

```c++
/***********************************************************************
* lookUpImpOrForward.
* The standard IMP lookup. 
* Without LOOKUP_INITIALIZE: tries to avoid +initialize (but sometimes fails)
* Without LOOKUP_CACHE: skips optimistic unlocked lookup (but uses cache elsewhere)
* Most callers should use LOOKUP_INITIALIZE and LOOKUP_CACHE
* inst is an instance of cls or a subclass thereof, or nil if none is known. 
*   If cls is an un-initialized metaclass then a non-nil inst is faster.
* May return _objc_msgForward_impcache. IMPs destined for external use 
*   must be converted to _objc_msgForward or _objc_msgForward_stret.
*   If you don't want forwarding at all, use LOOKUP_NIL.
**********************************************************************/
IMP lookUpImpOrForward(id inst, SEL sel, Class cls, int behavior)
{
    const IMP forward_imp = (IMP)_objc_msgForward_impcache;
    IMP imp = nil;
    Class curClass;

    runtimeLock.assertUnlocked();

    // Optimistic cache lookup
    if (fastpath(behavior & LOOKUP_CACHE)) {
        imp = cache_getImp(cls, sel);
        if (imp) goto done_nolock;
    }

    // runtimeLock is held during isRealized and isInitialized checking
    // to prevent races against concurrent realization.

    // runtimeLock is held during method search to make
    // method-lookup + cache-fill atomic with respect to method addition.
    // Otherwise, a category could be added but ignored indefinitely because
    // the cache was re-filled with the old value after the cache flush on
    // behalf of the category.

    runtimeLock.lock();

    // We don't want people to be able to craft a binary blob that looks like
    // a class but really isn't one and do a CFI attack.
    //
    // To make these harder we want to make sure this is a class that was
    // either built into the binary or legitimately registered through
    // objc_duplicateClass, objc_initializeClassPair or objc_allocateClassPair.
    //
    // TODO: this check is quite costly during process startup.
    checkIsKnownClass(cls);

    if (slowpath(!cls->isRealized())) {
        cls = realizeClassMaybeSwiftAndLeaveLocked(cls, runtimeLock);
        // runtimeLock may have been dropped but is now locked again
    }

    if (slowpath((behavior & LOOKUP_INITIALIZE) && !cls->isInitialized())) {
        cls = initializeAndLeaveLocked(cls, inst, runtimeLock);
        // runtimeLock may have been dropped but is now locked again

        // If sel == initialize, class_initialize will send +initialize and 
        // then the messenger will send +initialize again after this 
        // procedure finishes. Of course, if this is not being called 
        // from the messenger then it won't happen. 2778172
    }

    runtimeLock.assertLocked();
    curClass = cls;

    // The code used to lookpu the class's cache again right after
    // we take the lock but for the vast majority of the cases
    // evidence shows this is a miss most of the time, hence a time loss.
    //
    // The only codepath calling into this without having performed some
    // kind of cache lookup is class_getInstanceMethod().

    for (unsigned attempts = unreasonableClassCount();;) {
        // curClass method list.
        Method meth = getMethodNoSuper_nolock(curClass, sel);
        if (meth) {
            imp = meth->imp;
            goto done;
        }

        if (slowpath((curClass = curClass->superclass) == nil)) {
            // No implementation found, and method resolver didn't help.
            // Use forwarding.
            imp = forward_imp;
            break;
        }

        // Halt if there is a cycle in the superclass chain.
        if (slowpath(--attempts == 0)) {
            _objc_fatal("Memory corruption in class list.");
        }

        // Superclass cache.
        imp = cache_getImp(curClass, sel);
        if (slowpath(imp == forward_imp)) {
            // Found a forward:: entry in a superclass.
            // Stop searching, but don't cache yet; call method
            // resolver for this class first.
            break;
        }
        if (fastpath(imp)) {
            // Found the method in a superclass. Cache it in this class.
            goto done;
        }
    }

    // No implementation found. Try method resolver once.

    if (slowpath(behavior & LOOKUP_RESOLVER)) {
        behavior ^= LOOKUP_RESOLVER;
        return resolveMethod_locked(inst, sel, cls, behavior);
    }

 done:
    log_and_fill_cache(cls, imp, sel, inst, curClass);
    runtimeLock.unlock();
 done_nolock:
    if (slowpath((behavior & LOOKUP_NIL) && imp == forward_imp)) {
        return nil;
    }
    return imp;
}
```

`lookUpImpOrForward`æ–¹æ³•æ­£æ˜¯æ¶ˆæ¯æ…¢é€ŸæŸ¥æ‰¾çš„æ ¸å¿ƒæ‰€åœ¨

**é€è¡Œè®²è§£**

`runtimeLock.assertUnlocked()`æ˜¯åŠ ä¸€ä¸ªè¯»å†™é”ï¼Œä¿è¯çº¿ç¨‹å®‰å…¨

```c++
if (fastpath(behavior & LOOKUP_CACHE)) {
    imp = cache_getImp(cls, sel);
    if (imp) goto done_nolock;
}
```

ä¼šæ ¹æ®ä¼ å…¥çš„ `behavior & LOOKUP_CACHE` å€¼ï¼Œå¦‚æœå€¼ä¸ä¸º 0ï¼Œé‚£ä¹ˆä¼šè°ƒç”¨ `cache_getImp` æ–¹æ³•å»ä»ç¼“å­˜é‡Œé¢æŸ¥æ‰¾ impã€‚

â€‹	- å¦‚æœå­˜åœ¨ï¼Œåˆ™ä¼šè·³è½¬åˆ° `done_nolock`ï¼Œè¿”å› imp

```asm
	STATIC_ENTRY _cache_getImp

	GetClassFromIsa_p16 p0
	CacheLookup GETIMP, _cache_getImp

LGetImpMiss:
	mov	p0, #0
	ret

	END_ENTRY _cache_getImp
```

`checkIsKnownClass(cls)`æ˜¯åˆ¤æ–­å½“å‰ä¼ å…¥çš„ç±» cls æ˜¯å¦æ˜¯å·²çŸ¥çš„ç±»ï¼ˆç±»å·²ç»è¢«åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œè¿™ä¸ªä¼šåœ¨åé¢ç±»çš„åŠ è½½ä¸­å†ä½œä»‹ç»ï¼‰

```c++
if (slowpath(!cls->isRealized())) {
    cls = realizeClassMaybeSwiftAndLeaveLocked(cls, runtimeLock);
    // runtimeLock may have been dropped but is now locked again
}
```

`cls->isRealized()`åˆ¤æ–­ç±»æ˜¯å¦å·²ç»åˆå§‹åŒ–ï¼Œå¦‚æœæ²¡æœ‰åˆ™è°ƒç”¨`realizeClassMaybeSwiftAndLeaveLocked`æ–¹æ³•å»åˆå§‹åŒ–ç±»ã€çˆ¶ç±»ã€å…ƒç±»ç­‰ï¼Œå¹¶ä¸”ç”³è¯·ï¼Œè¿™æ˜¯ä¸º**æŸ¥æ‰¾æ–¹æ³•imp**åšå‡†å¤‡æ¡ä»¶

```c++
if (slowpath((behavior & LOOKUP_INITIALIZE) && !cls->isInitialized())) {
    cls = initializeAndLeaveLocked(cls, inst, runtimeLock);
    // runtimeLock may have been dropped but is now locked again

    // If sel == initialize, class_initialize will send +initialize and 
    // then the messenger will send +initialize again after this 
    // procedure finishes. Of course, if this is not being called 
    // from the messenger then it won't happen. 2778172
}
```



### æ€»ç»“


